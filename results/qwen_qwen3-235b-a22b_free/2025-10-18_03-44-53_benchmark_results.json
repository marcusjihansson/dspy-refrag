{
  "metadata": {
    "timestamp": "2025-10-18_03-44-53",
    "model_name": "qwen/qwen3-235b-a22b:free",
    "safe_model_name": "qwen_qwen3-235b-a22b_free",
    "parameters": {
      "k": 5,
      "budget": 2,
      "queries_count": 4
    },
    "environment": {
      "ollama_base": "http://localhost:11434",
      "ollama_model": "nomic-embed-text:latest",
      "openrouter_base": "https://openrouter.ai/api/v1",
      "github_base": "https://models.github.ai/inference",
      "github_model": "deepseek/DeepSeek-V3-0324"
    }
  },
  "benchmark_data": {
    "similarity": {
      "exact": 1.0,
      "jaccard": 1.0,
      "len_ratio": 1.0
    },
    "summary": {
      "Simple RAG": {
        "latency": {
          "avg": 0.5254636406898499,
          "median": 0.5396581888198853,
          "std": 0.2206986383037948,
          "p95": 0.7461098909378052,
          "min": 0.2760190963745117,
          "max": 0.7465190887451172
        },
        "tokens": {
          "avg": 0.0,
          "median": 0.0,
          "std": 0.0,
          "p95": 0.0,
          "min": 0.0,
          "max": 0.0
        },
        "context_chars": {
          "avg": 7503.0,
          "median": 7503.0,
          "std": 0.0,
          "p95": 7503.0,
          "min": 7503.0,
          "max": 7503.0
        },
        "prompt_chars": {
          "avg": 7614.5,
          "median": 7614.5,
          "std": 16.710774967068403,
          "p95": 7634.85,
          "min": 7591.0,
          "max": 7638.0
        },
        "retrieved": {
          "avg": 5.0,
          "median": 5.0,
          "std": 0.0,
          "p95": 5.0,
          "min": 5.0,
          "max": 5.0
        },
        "selected": {
          "avg": 0.0,
          "median": 0.0,
          "std": 0.0,
          "p95": 0.0,
          "min": 0.0,
          "max": 0.0
        }
      },
      "REFRAG": {
        "latency": {
          "avg": 0.23489344120025635,
          "median": 0.21121394634246826,
          "std": 0.04742689563533158,
          "p95": 0.30158832073211667,
          "min": 0.20098400115966797,
          "max": 0.3161618709564209
        },
        "tokens": {
          "avg": 0.0,
          "median": 0.0,
          "std": 0.0,
          "p95": 0.0,
          "min": 0.0,
          "max": 0.0
        },
        "context_chars": {
          "avg": 3023.0,
          "median": 3023.0,
          "std": 0.0,
          "p95": 3023.0,
          "min": 3023.0,
          "max": 3023.0
        },
        "prompt_chars": {
          "avg": 3134.5,
          "median": 3134.5,
          "std": 16.710774967068403,
          "p95": 3154.85,
          "min": 3111.0,
          "max": 3158.0
        },
        "retrieved": {
          "avg": 5.0,
          "median": 5.0,
          "std": 0.0,
          "p95": 5.0,
          "min": 5.0,
          "max": 5.0
        },
        "selected": {
          "avg": 2.0,
          "median": 2.0,
          "std": 0.0,
          "p95": 2.0,
          "min": 2.0,
          "max": 2.0
        }
      }
    },
    "queries": [
      "What is DSPy?",
      "What problem does 'programming, not prompting' aim to solve?",
      "List key components or modules in DSPy.",
      "How does DSPy integrate with LLMs?"
    ],
    "individual_results": {
      "simple_rag": [
        {
          "query": "What is DSPy?",
          "answer": "Error calling LM: Request failed: 400 Client Error: Bad Request for url: https://openrouter.ai/api/v1/chat/completions",
          "latency": 0.7465190887451172,
          "tokens": 0,
          "meta": {
            "retrieved": 5,
            "context_chars": 7503,
            "prompt_chars": 7591,
            "answer_chars": 118
          }
        },
        {
          "query": "What problem does 'programming, not prompting' aim to solve?",
          "answer": "Error calling LM: Request failed: 400 Client Error: Bad Request for url: https://openrouter.ai/api/v1/chat/completions",
          "latency": 0.3355252742767334,
          "tokens": 0,
          "meta": {
            "retrieved": 5,
            "context_chars": 7503,
            "prompt_chars": 7638,
            "answer_chars": 118
          }
        },
        {
          "query": "List key components or modules in DSPy.",
          "answer": "Error calling LM: Request failed: 400 Client Error: Bad Request for url: https://openrouter.ai/api/v1/chat/completions",
          "latency": 0.2760190963745117,
          "tokens": 0,
          "meta": {
            "retrieved": 5,
            "context_chars": 7503,
            "prompt_chars": 7617,
            "answer_chars": 118
          }
        },
        {
          "query": "How does DSPy integrate with LLMs?",
          "answer": "Error calling LM: Request failed: 400 Client Error: Bad Request for url: https://openrouter.ai/api/v1/chat/completions",
          "latency": 0.7437911033630371,
          "tokens": 0,
          "meta": {
            "retrieved": 5,
            "context_chars": 7503,
            "prompt_chars": 7612,
            "answer_chars": 118
          }
        }
      ],
      "refrag": [
        {
          "query": "What is DSPy?",
          "answer": "Error calling LM: Request failed: 400 Client Error: Bad Request for url: https://openrouter.ai/api/v1/chat/completions",
          "latency": 0.20342302322387695,
          "tokens": 0,
          "meta": {
            "retrieved": 5,
            "selected": 2,
            "context_chars": 3023,
            "prompt_chars": 3111
          }
        },
        {
          "query": "What problem does 'programming, not prompting' aim to solve?",
          "answer": "Error calling LM: Request failed: 400 Client Error: Bad Request for url: https://openrouter.ai/api/v1/chat/completions",
          "latency": 0.20098400115966797,
          "tokens": 0,
          "meta": {
            "retrieved": 5,
            "selected": 2,
            "context_chars": 3023,
            "prompt_chars": 3158
          }
        },
        {
          "query": "List key components or modules in DSPy.",
          "answer": "Error calling LM: Request failed: 400 Client Error: Bad Request for url: https://openrouter.ai/api/v1/chat/completions",
          "latency": 0.21900486946105957,
          "tokens": 0,
          "meta": {
            "retrieved": 5,
            "selected": 2,
            "context_chars": 3023,
            "prompt_chars": 3137
          }
        },
        {
          "query": "How does DSPy integrate with LLMs?",
          "answer": "Error calling LM: Request failed: 400 Client Error: Bad Request for url: https://openrouter.ai/api/v1/chat/completions",
          "latency": 0.3161618709564209,
          "tokens": 0,
          "meta": {
            "retrieved": 5,
            "selected": 2,
            "context_chars": 3023,
            "prompt_chars": 3132
          }
        }
      ]
    }
  }
}